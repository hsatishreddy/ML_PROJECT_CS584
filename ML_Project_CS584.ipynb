{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4273b36a",
   "metadata": {},
   "source": [
    "# Cyber Security Threat Detection Using Machine Learning Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c181400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/harshithareddy/Desktop')\n",
    "filename = 'output_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b89ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()  # Remove this line to enable eager execution\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7270e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Columns: 152 entries, 0 to 0.113\n",
      "dtypes: float64(4), int64(148)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "train = pd.read_csv(filename)\n",
    "train_data = train.copy()\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce18b78",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4b7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train_data.values\n",
    "X_train = array[:, 0:151]\n",
    "y_train = array[:, 151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9507be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 151)\n"
     ]
    }
   ],
   "source": [
    "# Split into a train and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=3)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792ac5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "#Checking train and validation sets still splits across the target evenly\n",
    "print(y_train.sum())\n",
    "print(y_valid.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77114b",
   "metadata": {},
   "source": [
    "### Normalise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf1bd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 151)\n"
     ]
    }
   ],
   "source": [
    "norm_scaler = MinMaxScaler(feature_range=(0, 1), clip=True).fit(X_train)\n",
    "n_X_train = norm_scaler.transform(X_train)\n",
    "print(n_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f4c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 151)\n"
     ]
    }
   ],
   "source": [
    "n_X_valid = norm_scaler.transform(X_valid)\n",
    "print(n_X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14a17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
